{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2407f639",
   "metadata": {},
   "source": [
    "Progress report (5%) – due 11:59pm on November 7th\n",
    "The progress report is a chance for you to take stock of how far you have come and to reflect on whether or not you are comfortable with the substance or scope of your final project. The format of the progress report will be a Jupyter notebook that should be uploaded to the private github repository you have set up for your team. It should include:\n",
    "- Include a link to your github project repository located in the Github Classroom designated for this course. We will check whether your github repository is created in the classroom set up for the course and whether all team members have been added there.\n",
    "\n",
    "- Project introduction: an introduction that discusses the data you are analyzing, and the question or questions you are investigating.\n",
    "- Any changes: a discussion whether your scope has changed since the check-in proposal slides. What did you aim to do that you will not do and what have you added to the project?\n",
    "- Data cleaning: show clearly how you cleaned your data.\n",
    "- Exploratory data analysis: explain what your data looks like (words are fine, but visualizations are often better). Include any interesting issues or preliminary conclusions you have about your data.\n",
    "- At least one visualization that tests an interesting hypothesis, along with an explanation about why you thought this was an interesting hypothesis to investigate.\n",
    "- At least one ML analysis on your dataset, along with a baseline comparison and an interpretation of the result that you obtain.\n",
    "- Reflection: a discussion of the following:\n",
    "    - What is the hardest part of the project that you’ve encountered so far?\n",
    "    - What are your initial insights?\n",
    "    - Are there any concrete results you can show at this point? If not, why not?\n",
    "    - Going forward, what are the current biggest problems you’re facing?\n",
    "    - Do you think you are on track with your project? If not, what parts do you need to dedicate more time to?\n",
    "    - Given your initial exploration of the data, is it worth proceeding with your project, why? If not, how are you going to change your project and why do you think it’s better than your current results?\n",
    "- Roles/Coordination (important): Who will be responsible for specific portions of the project (at least two for each portion is recommended): e.g., finding data sources, cleaning, statistical analysis, visualization, machine learning applications, etc.? What deadlines should various components of the project be completed by?\n",
    "- Next steps: What you plan to accomplish in the next month and how you plan to evaluate whether your project achieved the goals you set for it.\n",
    "\n",
    "What you need to submit: A PDF of your Jupyter notebook to Gradescope which includes a link to the notebook located in your repository (the two notebooks should look the same).\n",
    "\n",
    "How this part will be graded: the amount of progress that has been made, clarity of exposition. There will be a grade assigned to the whole progress report that everyone receives, and a grade assigned to you individually based on your github code contributions.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fd6a021",
   "metadata": {},
   "source": [
    "Github Link: https://github.com/cs418-fa24/project-check-in-team-8 "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86e185e3",
   "metadata": {},
   "source": [
    "PROJECT INTRODUCTION(MANU): \n",
    "\n",
    "Our project centers around analyzing NFL data from the 2024 season to uncover predictive indicators for Super Bowl success. By utilizing machine learning models, we aim to determine which team statistics correlate most strongly with playoff wins. Specifically, we’re investigating offensive stats like Passing Yards, Rushing Yards, and Receiving Yards, alongside defensive metrics such as Tackles and Interceptions, and team performance in terms of wins. This data is collected from ESPN using web scraping tools, then organized in a pandas DataFrame and exported to a CSV file for further analysis. Additionally, we’re delving into draft pick histories to evaluate the performance of quarterbacks based on their draft position, comparing higher and lower picks, and examining if backup quarterbacks outperform starters in the long run."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fad1e5d",
   "metadata": {},
   "source": [
    "ANY CHANGES(MANU): \n",
    "\n",
    "Since our initial proposal, we’ve refined the project scope to focus more narrowly on key offensive and defensive stats, instead of incorporating a wider array of advanced metrics. After discussing with our professor, we agreed to focus on six main statistics to ensure clarity in our analysis and predictive models. We’ve also added a historical comparison of quarterback draft picks, specifically those from 2015 to 2021, to explore if lower-drafted quarterbacks outperform higher picks over time and if backup quarterbacks show better performance metrics than starters. By narrowing our scope and adding these focused research questions, we aim to produce a robust and targeted analysis of what it takes to build a Super Bowl-winning team."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "727146b1",
   "metadata": {},
   "source": [
    "DATA CLEANING(GAGE): \n",
    "\n",
    "Since data was collected in a collaborative effort, most of the initial work that was required for further analysis consisted of combining the respective datasets into one CSV file, as well as cleaning the data itself. The column names of various initial files contained inconsistencies which had to be dealt with prior to combining (\"Pass Attempts\" vs \"Passing Attempts\", \"Cmp_Pct\" vs \"Completion Percentage\", etc). Once these files were combined, any potential null values were checked and amended to 0, or the appropriate value."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "883bb779",
   "metadata": {},
   "source": [
    "EXPLORATORY DATA ANALYSIS(GAGE): \n",
    "\n",
    "Our primary goal is to explore any correlation between a quarterback’s draft position and their performance as indicated by metrics such as average QBR and win rate. The scatter plot below shows draft pick position on the x-axis and average QBR on the y-axis. A downward trend could indicate that quarterbacks picked earlier tend to have higher QBRs, while a lack of trend might suggest that draft position does not strongly correlate with QBR. Additionally, win rate and passing yards are indicated by the color and size of each dot, respectively. This visualization gives a great initial exploration of the nature of the data and give us a loose understanding from a quick glance: which is to say that quarterbacks that are drafted higher generally experience more success, indicated by their higher win rate, QBR, and passing yardage. Outliers tend to favor underdogs overperforming their value as opposed to the high draft picks failing to meet theirs."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d7f1d5d",
   "metadata": {},
   "source": [
    "![Draft Pick vs Avg QBR & Win Rate](DraftPickvsAvgQBRWinRate.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f2d733e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#ONE VISUALIZATOIN(VASU)\n",
    "\n",
    "#import any necessary libraries here\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "id": "78f0133a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-08T00:58:37.080255Z",
     "start_time": "2024-11-08T00:58:37.069898Z"
    }
   },
   "source": [
    "#ML ANALYSIS(SHRINIKET AND CARLOS)\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits import mplot3d\n",
    "from sklearn.linear_model import LinearRegression, LogisticRegression\n",
    "\n",
    "nfl_qb_stats = pd.read_csv('combinedQBStats.csv')\n",
    "\n",
    "mean_qbr_by_draft_pick = nfl_qb_stats.groupby(\"Draft Pick\")[[\"QBR\"]].mean().reset_index()\n",
    "# print(mean_qbr_by_draft_pick)\n",
    "X = mean_qbr_by_draft_pick[\"Draft Pick\"].values.reshape(-1, 1)\n",
    "y = mean_qbr_by_draft_pick[[\"QBR\"]]\n",
    "\n",
    "## Actual Model being used\n",
    "linear_regression = LinearRegression()\n",
    "linear_regression.fit(X, np.ravel(y))\n",
    "linear_model_predictions = linear_regression.predict(X)\n",
    "print(f\"Linear Model predictions {linear_model_predictions}\")\n",
    "\n",
    "## Baseline model\n",
    "m = -1\n",
    "b = 90\n",
    "list_of_y = []\n",
    "for i in X:\n",
    "    y = m * (i[0]) + b\n",
    "    if y < 0:\n",
    "        list_of_y.append(0)\n",
    "    else:\n",
    "        list_of_y.append(int(y))\n",
    "\n",
    "print(f\"Baseline Model {list_of_y}\")\n",
    "# for i in range(1, 250):\n",
    "#     print(linear_regression.predict(X))\n",
    "\n",
    "\n",
    "\n",
    "#WRITE YOUR CODE HERE"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linear Model predictions [84.73062916 84.52711105 84.32359295 83.91655673 83.71303863 83.50952052\n",
      " 82.8989662  82.6954481  82.49192999 81.88137567 79.64267651 78.42156787\n",
      " 76.38638681 74.35120575 74.14768765 71.90898848 71.50195227 71.29843416\n",
      " 69.67028932 69.46677121 67.22807205 66.82103583 66.41399962 66.00696341\n",
      " 64.58233667 63.97178235 63.76826424 62.95419182 57.86623917 57.45920296\n",
      " 56.64513054 51.9642141  51.15014167 50.94662357 50.13255114 48.7079244\n",
      " 46.87626145 46.46922524 46.06218902 44.84108039 44.43404418 44.02700797\n",
      " 42.80589933 40.56720016 37.92146479 34.25813888 33.44406645]\n",
      "Baseline Model [89, 88, 87, 85, 84, 83, 80, 79, 78, 75, 64, 58, 48, 38, 37, 26, 24, 23, 15, 14, 3, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n"
     ]
    }
   ],
   "execution_count": 30
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Based on the \"predicted\" results for the baseline model and Linear regression it seems that Linear regression seems to be better suited for our dataset. We are looking for results where stats are among the highest when draft picks are higher. We are using QBR in this situation although most stats should be higher when given a high draft pick (except for interceptions). The baseline model goes to 0 after a certain arbitary draft pick, when there could always exist anomalies or outliers. Since football is such a dynamic sport, outliers are  present and linear regression accounts for this. Thus linear regression is the best ML model for this situation. ",
   "id": "60fa931166ec7940"
  },
  {
   "cell_type": "markdown",
   "id": "d08e9103",
   "metadata": {},
   "source": [
    "REFLECTION(ZEESHAN): \n",
    "\n",
    "Some difficulties with the project so far have been the large variance within the data, as our sample size is focused on just quarterbacks over the last few years. Because of the constantly changing offensive environment in the league, it's difficult to compare across eras which means our data must be concentrated on modern QBs. This in turn limits the amount of data we can use to compare and make valid conclusions with. The initial insights we've seen have matched up with logical thinking; quarterbacks who were drafted higher have, on average, higher passer ratings. This would make sense as a higher draft pedigree usually correlates with better performance in the league. There's also a large concentration of QBs who are taken very early in the draft, thinning out in occurrence as the rounds progress. This also lines up with conventional football wisdom, which deems the quarterback the most valuable player on the team. Even those who are not worth high draft pick capital are taken earlier than an equivalent skill player because of the positional value. \n",
    "\n",
    "Some issues which could prevent further data exploration include the aforementioned variance within our data set, which could cause some data analysis to be flawed. This shouldn't be an issue if we focus on game-by-game stats and comparisons, as we have plenty of those. But overall career comparisons become much trickier. There's also a lot of context which is sometimes necessary to evaluate performance, which can't be quantified. Injuries can limit a start and cut the statistical numbers down, which isn't accounted for. Overall though, it should'nt pose a big issue and we are on track with our project. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4d198f8",
   "metadata": {},
   "source": [
    "ROLES/COORDINATION(VASU): \n",
    "\n",
    "WRITE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fca77bce",
   "metadata": {},
   "source": [
    "NEXT STEPS(YUGESH AND ZEESHAN):\n",
    "\n",
    "WRITE HERE"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
